{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing with Disaster Tweets\n",
    "#### By: Niv Dobzinski (PhD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T05:53:19.083145Z",
     "iopub.status.busy": "2024-05-28T05:53:19.082787Z",
     "iopub.status.idle": "2024-05-28T05:53:19.092031Z",
     "shell.execute_reply": "2024-05-28T05:53:19.091164Z",
     "shell.execute_reply.started": "2024-05-28T05:53:19.083113Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from torch.nn import DataParallel\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T05:53:19.093540Z",
     "iopub.status.busy": "2024-05-28T05:53:19.093253Z",
     "iopub.status.idle": "2024-05-28T05:53:19.145064Z",
     "shell.execute_reply": "2024-05-28T05:53:19.144179Z",
     "shell.execute_reply.started": "2024-05-28T05:53:19.093514Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data loading and preprocessing\n",
    "train_file = \"/kaggle/input/nlp-getting-started/train.csv\"\n",
    "test_file = \"/kaggle/input/nlp-getting-started/test.csv\"\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_df = pd.read_csv(test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values with a placeholder token UNK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T05:53:19.148118Z",
     "iopub.status.busy": "2024-05-28T05:53:19.147791Z",
     "iopub.status.idle": "2024-05-28T05:53:19.164472Z",
     "shell.execute_reply": "2024-05-28T05:53:19.163563Z",
     "shell.execute_reply.started": "2024-05-28T05:53:19.148092Z"
    }
   },
   "outputs": [],
   "source": [
    "y = train_df['target']\n",
    "X = train_df.drop(columns=['target'])\n",
    "\n",
    "X['keyword'] = X['keyword'].fillna('[UNK]')\n",
    "X['location'] = X['location'].fillna('[UNK]')\n",
    "test_df['keyword'] = test_df['keyword'].fillna('[UNK]')\n",
    "test_df['location'] = test_df['location'].fillna('[UNK]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text ckeaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T05:53:19.166828Z",
     "iopub.status.busy": "2024-05-28T05:53:19.165776Z",
     "iopub.status.idle": "2024-05-28T05:53:19.733194Z",
     "shell.execute_reply": "2024-05-28T05:53:19.732236Z",
     "shell.execute_reply.started": "2024-05-28T05:53:19.166801Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\[unk\\]', 'PLACEHOLDERUNK', text)\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    text = re.sub(r'PLACEHOLDERUNK', '[UNK]', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "X['text'] = X['text'].apply(clean_text)\n",
    "X['keyword'] = X['keyword'].apply(clean_text)\n",
    "X['location'] = X['location'].apply(clean_text)\n",
    "test_df['text'] = test_df['text'].apply(clean_text)\n",
    "test_df['keyword'] = test_df['keyword'].apply(clean_text)\n",
    "test_df['location'] = test_df['location'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatinate the columns text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T05:53:19.734782Z",
     "iopub.status.busy": "2024-05-28T05:53:19.734473Z",
     "iopub.status.idle": "2024-05-28T05:53:19.749792Z",
     "shell.execute_reply": "2024-05-28T05:53:19.748604Z",
     "shell.execute_reply.started": "2024-05-28T05:53:19.734754Z"
    }
   },
   "outputs": [],
   "source": [
    "X['combined'] = '[KEYWORD] ' + X['keyword'] + ' [LOCATION] ' + X['location'] + ' [TEXT] ' + X['text']\n",
    "test_df['combined'] = '[KEYWORD] ' + test_df['keyword'] + ' [LOCATION] ' + test_df['location'] + ' [TEXT] ' + test_df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-23T08:51:33.637068Z",
     "iopub.status.busy": "2024-05-23T08:51:33.636054Z",
     "iopub.status.idle": "2024-05-23T08:51:33.644878Z",
     "shell.execute_reply": "2024-05-23T08:51:33.642787Z",
     "shell.execute_reply.started": "2024-05-23T08:51:33.637028Z"
    }
   },
   "source": [
    "### Split dataset and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T05:53:19.751586Z",
     "iopub.status.busy": "2024-05-28T05:53:19.751214Z",
     "iopub.status.idle": "2024-05-28T05:53:28.584297Z",
     "shell.execute_reply": "2024-05-28T05:53:28.583201Z",
     "shell.execute_reply.started": "2024-05-28T05:53:19.751552Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "def tokenize_texts(texts, labels=None):\n",
    "    tokenized_data = tokenizer(texts, padding=\"max_length\", truncation=True, return_tensors='pt')\n",
    "    if labels is not None:\n",
    "        return tokenized_data['input_ids'], tokenized_data['attention_mask'], torch.tensor(labels)\n",
    "    return tokenized_data['input_ids'], tokenized_data['attention_mask']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X['combined'], y, test_size=0.2, random_state=42)\n",
    "train_inputs, train_masks, train_labels = tokenize_texts(X_train.tolist(), y_train.tolist())\n",
    "val_inputs, val_masks, val_labels = tokenize_texts(X_val.tolist(), y_val.tolist())\n",
    "test_inputs, test_masks = tokenize_texts(test_df['combined'].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T05:53:28.585798Z",
     "iopub.status.busy": "2024-05-28T05:53:28.585498Z",
     "iopub.status.idle": "2024-05-28T05:53:28.591107Z",
     "shell.execute_reply": "2024-05-28T05:53:28.590082Z",
     "shell.execute_reply.started": "2024-05-28T05:53:28.585772Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "val_dataset = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "test_dataset = TensorDataset(test_inputs, test_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T05:53:28.592741Z",
     "iopub.status.busy": "2024-05-28T05:53:28.592440Z",
     "iopub.status.idle": "2024-05-28T05:53:28.603872Z",
     "shell.execute_reply": "2024-05-28T05:53:28.602787Z",
     "shell.execute_reply.started": "2024-05-28T05:53:28.592715Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
    "# Generate target modules\n",
    "target_modules = []\n",
    "for layer in range(12):\n",
    "    for sub_module in ['query', 'key', 'value']:\n",
    "#         target_modules.append(f'bert.encoder.layer.{layer}.attention.self.{sub_module}')\n",
    "        target_modules.append(f'roberta.encoder.layer.{layer}.attention.self.{sub_module}')\n",
    "# Config Lora\n",
    "lora_config = LoraConfig(\n",
    "    target_modules=target_modules,\n",
    "    r=4,  # rank of the low-rank approximation\n",
    "    lora_alpha=32,  # scaling factor\n",
    "    lora_dropout=0.1  # dropout rate for LoRA layers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap model with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T05:53:28.988031Z",
     "iopub.status.busy": "2024-05-28T05:53:28.987720Z",
     "iopub.status.idle": "2024-05-28T05:53:29.046743Z",
     "shell.execute_reply": "2024-05-28T05:53:29.045852Z",
     "shell.execute_reply.started": "2024-05-28T05:53:28.988004Z"
    }
   },
   "outputs": [],
   "source": [
    "lora_model = get_peft_model(model, lora_config)\n",
    "lora_model = DataParallel(lora_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enable GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lora_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and Loss parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T05:53:29.197464Z",
     "iopub.status.busy": "2024-05-28T05:53:29.197096Z",
     "iopub.status.idle": "2024-05-28T05:53:29.206472Z",
     "shell.execute_reply": "2024-05-28T05:53:29.205529Z",
     "shell.execute_reply.started": "2024-05-28T05:53:29.197434Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(lora_model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "accumulation_steps = 1  # Number of steps to accumulate gradients\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T05:53:29.207984Z",
     "iopub.status.busy": "2024-05-28T05:53:29.207628Z",
     "iopub.status.idle": "2024-05-28T06:02:16.796372Z",
     "shell.execute_reply": "2024-05-28T06:02:16.795268Z",
     "shell.execute_reply.started": "2024-05-28T05:53:29.207958Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4: 100%|██████████| 191/191 [02:00<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4, Train Loss: 0.0216, Validation Loss: 0.0213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/4: 100%|██████████| 191/191 [01:59<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4, Train Loss: 0.0184, Validation Loss: 0.0149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/4: 100%|██████████| 191/191 [01:59<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/4, Train Loss: 0.0143, Validation Loss: 0.0136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/4: 100%|██████████| 191/191 [01:59<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/4, Train Loss: 0.0134, Validation Loss: 0.0131\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 4\n",
    "lora_model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")):\n",
    "        inputs, attention_masks, labels = batch\n",
    "        inputs, attention_masks, labels = inputs.to(device), attention_masks.to(device), labels.to(device)\n",
    "\n",
    "        with autocast():\n",
    "            outputs = lora_model(input_ids=inputs, attention_mask=attention_masks).logits\n",
    "            loss = loss_fn(outputs, labels) / accumulation_steps\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item() * accumulation_steps\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader.dataset)\n",
    "\n",
    "    # Validation step\n",
    "    lora_model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs, attention_masks, labels = batch\n",
    "            inputs, attention_masks, labels = inputs.to(device), attention_masks.to(device), labels.to(device)\n",
    "            with autocast():\n",
    "                outputs = lora_model(input_ids=inputs, attention_mask=attention_masks).logits\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    lora_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T06:02:16.797933Z",
     "iopub.status.busy": "2024-05-28T06:02:16.797613Z",
     "iopub.status.idle": "2024-05-28T06:02:43.129306Z",
     "shell.execute_reply": "2024-05-28T06:02:43.128218Z",
     "shell.execute_reply.started": "2024-05-28T06:02:16.797905Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 48/48 [00:26<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8220617202889035\n",
      "Validation Precision: 0.7990506329113924\n",
      "Validation Recall: 0.7781201848998459\n",
      "Validation F1 Score: 0.7884465261514442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8220617202889035,\n",
       " 0.7990506329113924,\n",
       " 0.7781201848998459,\n",
       " 0.7884465261514442)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(model, val_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations\n",
    "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            inputs, attention_masks, labels = batch\n",
    "            inputs, attention_masks, labels = inputs.to(device), attention_masks.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(input_ids=inputs, attention_mask=attention_masks).logits\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Validation Accuracy: {accuracy}\")\n",
    "    print(f\"Validation Precision: {precision}\")\n",
    "    print(f\"Validation Recall: {recall}\")\n",
    "    print(f\"Validation F1 Score: {f1}\")\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(lora_model, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T06:02:43.131092Z",
     "iopub.status.busy": "2024-05-28T06:02:43.130754Z",
     "iopub.status.idle": "2024-05-28T06:02:43.138481Z",
     "shell.execute_reply": "2024-05-28T06:02:43.137361Z",
     "shell.execute_reply.started": "2024-05-28T06:02:43.131064Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to predict on the test dataset\n",
    "def predict_test(model, test_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations\n",
    "        for batch in tqdm(test_loader, desc=\"Predicting\"):\n",
    "            inputs, attention_masks = batch\n",
    "            inputs, attention_masks = inputs.to(device), attention_masks.to(device)\n",
    "\n",
    "            outputs = model(input_ids=inputs, attention_mask=attention_masks).logits\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T06:02:43.140131Z",
     "iopub.status.busy": "2024-05-28T06:02:43.139763Z",
     "iopub.status.idle": "2024-05-28T06:03:39.548797Z",
     "shell.execute_reply": "2024-05-28T06:03:39.547768Z",
     "shell.execute_reply.started": "2024-05-28T06:02:43.140090Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 102/102 [00:56<00:00,  1.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test dataset\n",
    "test_predictions = predict_test(lora_model, test_loader)\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_df['id'],  # Assuming 'id' column is present in test_df\n",
    "    'target': test_predictions\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Competition Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Kaggle Competition Accuracy Score:** 0.819\n",
    "\n",
    "![Kaggle Score](Kaggle_compatition_score.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 869809,
     "sourceId": 17777,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
